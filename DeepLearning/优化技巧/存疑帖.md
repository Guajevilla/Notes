# 存疑帖
## faster RCNN

参考[知乎上的这个答案](https://www.zhihu.com/question/42205480/answer/525212289)很详细。

![](_v_images/20190513153125060_11976.png =650x)
**faster RCNN中anchor和proposal关系？**
&emsp;&emsp;每个anchor是预测proposal坐标网络的标签。

**原文中anchor面积指的是映射到原图上的面积？**
&emsp;&emsp;是这样的。另外论文中的那张图是对于一个3\*3的区域来说，生成的是256维向量(ZFnet)。假设最后一层特征图w\*h，原图W\*H，则W = S * w, H = S * h；S为stride。

**RPN网络的输出？**
&emsp;&emsp;某个anchor是前景还是后景。
&emsp;&emsp;该anchor对应的bounding box对应坐标。

**但此处坐标(x,y,w,h)对应的是feature map上？还是原图上？这个坐标怎么输入最后的分类网络？**
&emsp;&emsp;应该是原图，训练的label来自于anchor的变化。

**RPN网络输出的bounding box空间信息从哪里来？BB的位置肯定是基于原图像的，你RPN是所有图共享的一个，其输入不管怎么说只是一个图像的一部分，而且网络还不知道是哪一部分，空间信息从哪来的？**
&emsp;&emsp;空间信息来自于周围各个像素点？

**bounding box regression运行在什么基础上？网络最终输出的BB经过了几次回归器？**
&emsp;&emsp;第一个回归是针对正样本anchor对应的ground truth的回归。

## mask RCNN
**双线性插值的图是不是错了？**
&emsp;&emsp;
## FPN
**语义semantic与conv net深度的关系？为什么说不同深度会引起的较大的语义gap？**
&emsp;&emsp;

**为什么说为了避免使用低级特征，SSD放弃重用已经计算好的图层，而从网络中的最高层开始构建金字塔（例如，VGG网络的conv4_3[36]），然后添加几个新层。因此它错过了重用特征层级的更高分辨率映射的机会。**
&emsp;&emsp;

**为什么传统featurizing each level of an image pyramid会有内存上的问题而FPN不会？**
&emsp;&emsp;

**关于自上而下和自下而上网络相加的时候降维问题**
![](_v_images/20190514094908057_4794.png =640x)
&emsp;&emsp;关于两个网络的维度，唯一不同需要调整的是深度方向。因为分类器每层都是共享的，FPN每层深度需要相同，设为d。所以个人理解的是前馈网络通过1\*1卷积升降维到256，自上而下的网络第一层来自C5，将C5进行1\*1降维到256即可得到P5。
## FCN

## YOLO
**最后两层按原文说是全连接层，全连接层怎么由一个4096维向量变成7\*7\*30张量的？**
&emsp;&emsp;

**训练过程以及损失函数中的各个标签？**
&emsp;&emsp;

**WordTree？**
&emsp;&emsp;